package resolvers

// This file will be automatically regenerated based on the schema, any resolver implementations
// will be copied through when generating and any unknown code will be moved to the end.
// Code generated by github.com/99designs/gqlgen version v0.17.49

import (
	"context"
	"errors"
	"fmt"
	"io"

	"github.com/99designs/gqlgen/graphql/handler/transport"
	"github.com/lingticio/llmg/internal/graph/openai/generated"
	"github.com/lingticio/llmg/internal/graph/openai/model"
	"github.com/lingticio/llmg/internal/graph/server/middlewares"
	"github.com/samber/lo"
	"github.com/sashabaranov/go-openai"
	"github.com/vektah/gqlparser/v2/gqlerror"
	"go.uber.org/zap"
)

// CreateChatCompletion is the resolver for the createChatCompletion field.
func (r *mutationResolver) CreateChatCompletion(ctx context.Context, input model.CreateChatCompletionInput) (*model.ChatCompletionResult, error) {
	apiKey := middlewares.APIKeyFromContext(ctx)

	config := openai.DefaultConfig(apiKey)
	baseURL := middlewares.XBaseURLFromContext(ctx)
	if baseURL != "" {
		config.BaseURL = baseURL
	}

	client := openai.NewClientWithConfig(config)

	openaiResponse, err := client.CreateChatCompletion(ctx, inputToRequest(input, false))
	if err != nil {
		return nil, err
	}

	response := &model.ChatCompletionResult{
		ID:      openaiResponse.ID,
		Object:  openaiResponse.Object,
		Created: int(openaiResponse.Created),
		Model:   openaiResponse.Model,
		Choices: lo.Map(openaiResponse.Choices, func(item openai.ChatCompletionChoice, index int) *model.ChatCompletionChoice {
			choice := &model.ChatCompletionChoice{
				Index:        item.Index,
				Message:      mapMessage(item.Message),
				FinishReason: lo.ToPtr(model.FinishReason(item.FinishReason)),
			}
			if item.LogProbs != nil {
				choice.LogProbs = new(model.LogProbs)
			}
			if item.LogProbs != nil && item.LogProbs.Content != nil {
				choice.LogProbs.Content = logProbsToTokenLogProbs(item.LogProbs.Content)
			}

			return choice
		}),
		SystemFingerprint: lo.ToPtr(openaiResponse.SystemFingerprint),
		Usage: &model.Usage{
			PromptTokens:     openaiResponse.Usage.PromptTokens,
			CompletionTokens: openaiResponse.Usage.CompletionTokens,
			TotalTokens:      openaiResponse.Usage.TotalTokens,
		},
	}

	return response, nil
}

// Models is the resolver for the models field.
func (r *queryResolver) Models(ctx context.Context, first *int, after *string, last *int, before *string) (*model.ModelConnection, error) {
	panic(fmt.Errorf("not implemented: Models - models"))
}

// CreateChatCompletionStream is the resolver for the createChatCompletionStream field.
func (r *subscriptionResolver) CreateChatCompletionStream(ctx context.Context, input model.CreateChatCompletionInput) (<-chan *model.ChatCompletionStreamResult, error) {
	apiKey := middlewares.APIKeyFromContext(ctx)

	config := openai.DefaultConfig(apiKey)
	baseURL := middlewares.XBaseURLFromContext(ctx)
	if baseURL != "" {
		config.BaseURL = baseURL
	}

	client := openai.NewClientWithConfig(config)

	ch := make(chan *model.ChatCompletionStreamResult)

	stream, err := client.CreateChatCompletionStream(ctx, inputToRequest(input, true))
	if err != nil {
		r.Logger.Error("failed to create chat completion stream", zap.Error(err))
		return nil, err
	}

	go func() {
		for {
			response, err := stream.Recv()
			if errors.Is(err, io.EOF) {
				r.Logger.Info("stream closed")

				close(ch)
				break
			}
			if err != nil {
				r.Logger.Error("failed to receive chat completion stream", zap.Error(err))
				transport.AddSubscriptionError(ctx, &gqlerror.Error{
					Message: err.Error(),
				})

				close(ch)
				break
			}

			result := &model.ChatCompletionStreamResult{
				ID:      response.ID,
				Object:  response.Object,
				Created: int(response.Created),
				Model:   response.Model,
				Choices: lo.Map(response.Choices, func(item openai.ChatCompletionStreamChoice, index int) *model.ChatCompletionStreamChunkChoice {
					choice := &model.ChatCompletionStreamChunkChoice{
						Index:        item.Index,
						Delta:        mapDelta(item.Delta),
						FinishReason: lo.ToPtr(model.FinishReason(item.FinishReason)),
					}

					return choice
				}),
				SystemFingerprint: lo.ToPtr(response.SystemFingerprint),
			}
			if response.Usage != nil {
				result.Usage = &model.Usage{
					PromptTokens:     response.Usage.PromptTokens,
					CompletionTokens: response.Usage.CompletionTokens,
					TotalTokens:      response.Usage.TotalTokens,
				}
			}

			ch <- result
		}
	}()

	return ch, nil
}

// Mutation returns generated.MutationResolver implementation.
func (r *Resolver) Mutation() generated.MutationResolver { return &mutationResolver{r} }

// Query returns generated.QueryResolver implementation.
func (r *Resolver) Query() generated.QueryResolver { return &queryResolver{r} }

// Subscription returns generated.SubscriptionResolver implementation.
func (r *Resolver) Subscription() generated.SubscriptionResolver { return &subscriptionResolver{r} }

type mutationResolver struct{ *Resolver }
type queryResolver struct{ *Resolver }
type subscriptionResolver struct{ *Resolver }
